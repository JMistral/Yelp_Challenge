{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0Qc1THNHSapDL7cv-ZzW5g</td>\n",
       "      <td>5</td>\n",
       "      <td>What can I say.. Wowzers! Probably one of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4LxKRRIikhr65GfPDW626w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>L8lo5SKXfZRlbn1bpPiC9w</td>\n",
       "      <td>5</td>\n",
       "      <td>Went here for guys weekend. Unbelievable. Ravi...</td>\n",
       "      <td>0</td>\n",
       "      <td>nT8zgjoc-PbdBoQsFEXFLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>30</td>\n",
       "      <td>6eUT3IwwWPP3CZkAhxqOIw</td>\n",
       "      <td>5</td>\n",
       "      <td>One word my friends: tableside!!! Yes, tablesi...</td>\n",
       "      <td>56</td>\n",
       "      <td>7RlyCglsIzhBn081inwvcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>3cnTdE45VrsS0o4cVhfGog</td>\n",
       "      <td>3</td>\n",
       "      <td>Located inside my favorite hotel Venetian, Del...</td>\n",
       "      <td>1</td>\n",
       "      <td>rOIrilMC7VFwFVBeQNiKMw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>tYrSbjX3QgZGBZuQ3n8g6w</td>\n",
       "      <td>5</td>\n",
       "      <td>After the most incredible service, delicious m...</td>\n",
       "      <td>2</td>\n",
       "      <td>PiWlV_UC_-SXqyxQM9fAtw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                                       categories  avg_stars  cool  \\\n",
       "0  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     1   \n",
       "1  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     0   \n",
       "2  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0    52   \n",
       "3  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     1   \n",
       "4  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     0   \n",
       "\n",
       "         date  funny               review_id  stars  \\\n",
       "0  2016-05-17      0  0Qc1THNHSapDL7cv-ZzW5g      5   \n",
       "1  2017-01-20      0  L8lo5SKXfZRlbn1bpPiC9w      5   \n",
       "2  2016-09-25     30  6eUT3IwwWPP3CZkAhxqOIw      5   \n",
       "3  2017-02-12      0  3cnTdE45VrsS0o4cVhfGog      3   \n",
       "4  2016-10-30      0  tYrSbjX3QgZGBZuQ3n8g6w      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  What can I say.. Wowzers! Probably one of the ...       0   \n",
       "1  Went here for guys weekend. Unbelievable. Ravi...       0   \n",
       "2  One word my friends: tableside!!! Yes, tablesi...      56   \n",
       "3  Located inside my favorite hotel Venetian, Del...       1   \n",
       "4  After the most incredible service, delicious m...       2   \n",
       "\n",
       "                  user_id  \n",
       "0  4LxKRRIikhr65GfPDW626w  \n",
       "1  nT8zgjoc-PbdBoQsFEXFLw  \n",
       "2  7RlyCglsIzhBn081inwvcg  \n",
       "3  rOIrilMC7VFwFVBeQNiKMw  \n",
       "4  PiWlV_UC_-SXqyxQM9fAtw  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = [t for i,t in enumerate(df.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277219"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect your documents, e.g. check the size, take a peek at elements of the numpy array\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the target variable (any categorical variable that may be meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, I am interested in perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eba19b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a column and take the values, save to a variable named \"target\"\n",
    "df.target = df.stars\n",
    "import numpy as np\n",
    "np.median(df.target)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.target.plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You may want to look at the statistic of the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    277219.00000\n",
       "mean          0.47206\n",
       "std           0.49922\n",
       "min           0.00000\n",
       "25%           0.00000\n",
       "50%           0.00000\n",
       "75%           1.00000\n",
       "max           1.00000\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "df.target = df.stars.apply(lambda x: 1 if x > 4 else 0)\n",
    "df.target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessie/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(\n",
    "     documents, df.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform your test data\n",
    "vectors_test = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We will need these helper methods pretty soon\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    return  [labels[i] for i in np.argsort(lst)[::1][:n]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "doc_test = documents_test[np.random.randint(len(documents_test), size=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "doc_test_vector = vectorizer.transform([doc_test]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "similarity_scores = cosine_similarity(doc_test_vector, vectors_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "#np.shape(similarity_scores[0])\n",
    "searched_result = get_top_values(similarity_scores[0], n, documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "Had to come check this place out, I'd never had a fresh White Castle burger and I was not disappointed. I got the 4 cheeseburgers with fries and a drink, it tasted fresh and was nice and hot. The onions were a tasty addition and even though I could only finish three of the burgers and half the fries, it was really tasty! Would definitely go back.\n"
     ]
    }
   ],
   "source": [
    "print ('Our search query:')\n",
    "print (doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 5 similar reviews:\n",
      "[\"After walking up and down the Strip twice I was craving some White Castle almost as much as Roldy and Kumar!\\n\\nFrom the outside it looked like a tiny standalone but actually the location is inside the Casino Royale.\\n\\nGot the #7 Castle Pack, which was 10 sliders, two regular fries and two drinks.\\n\\nService was good as they got my order out quickly in spite of the place being packed but for my first time eating White Castle burgers at a White Castle I was rather disappointed. \\n\\nThese certainly did not hit the spot! I know sliders don't have much meat but these were practically meatless! And the onions could've tasted a whole lot better. The Fries were meh too as they were a bit soggy.\\n\\nNot gonna lie, I enjoyed the microwave White Castle burgers you get from the grocery better...\", 'After a night of dancing, my friends and I went to White Castle. No regrets.\\n\\nI have had White Castle burgers in the past. From the freezer section at the supermarket. I have always wonder if they are really that, uh, good, in real life. After Tao, we stopped at White Castle and bought the 20 piece combo with fries and chicken rings. Yes, chicken rings. \\n\\nThe verdict: White Castle burgers taste just like the burgers you get out of the freezer aisle. They were pretty damn satisfying and tasty. The fries were good and the chicken rings were definitely questionable. I would definitely go back!', \"Been wanting to venture out to White Castle for about a decade now. Ever since Harold and Kumar made their voyage, I've been anticipating my own. Had a few days off from work and figured it was time to try these burgers fresh, instead of the ones from the frozen food section that I have once in a while.\\n\\nWalking down the strip towards White Castle was awesome and exciting but when I finally pulled out my first slider my excitement faded a bit (not much, it's Vegas!). The bread was very soggy and they tasted about the same as the frozen ones to me. Though these had more cheese. Was expecting a fresh White Castle patty to be tastier. Maybe this just isn't a great location. I'm definitely trying White Castle again if I ever encounter another chain.\\n\\nIf you happen to stop by a White Castle I would firstly advise you not to settle for this and turn away. Vegas has so many better options! What? Sorry! If you're on some quest like me or just dgaf than I'd recommend asking for a toasted bun if you choose to eat here. It is a cool experience to have if you are a fan of the Harold and Kumar movies, but beyond that these burgers are kinda average (both frozen ones and these).\\n\\nWhile the burger itself wasn't what i was hoping for, I was still glad I made the drive to White Castle. It was an experience I knew I wanted to have and though the burgers weren't satisfying, the overall experience was fun. Oh yeah and the fries were meh too. Though crispy. Throw some Cajun Seasoning on them sumbitches or something! Thank God for Ketchup. \\n\\nPros:\\n+ Staff was nice\\n\\nCons:\\n- Bun was very soggy\\n- Fries were bland\\n- Location could have been cleaner (several dirty tables)\", \"For over 30 years I've been hearing about White Castle sliders from those that lived in, or traveled to parts of the country that offered them. Then, after Harold and Kumar made their movie, I truly hoped that one day I would travel to a place in the mid west or eastern parts that had a White Castle Burger joint, or even better, I wished that White Castle would open a store here in Southern California. Sadly, no luck either way. Then voila! I saw them in the frozen section of my local super market. I bought a pack, took them home and immediately nuked a few in the microwave. Not bad I thought to myself. They had a unique flavor with kind of an onion tang. Nevertheless, these were frozen burgers. I knew the freshly made ones had to be better, so I withheld final judgement, and continued to hope for a real experience at a White Castle location.\\n\\nFast forward several years and I'm walking the strip in Las Vegas and the White Castle sign hit my like a ton of bricks! There it  was! Boom! A real deal White Castle burger joint right here in Las Vegas, and right in front of me! I dragged the wife into the place and immediately placed an order for sliders, fries and a drink. So let me get this out of the way first, I don't like krinkle fries. And, the White Castle krinkle fries were no different than any other krinkle fries I've tried. So what did I think of the sliders? They were really tasty and much better than the frozen ones, as I expected them to be. These are truly unique sliders. They are steamed with the onion on the patties. I think that's part of what makes them distinctive.\\n\\nNow, if I'm only judging the slider, in the context of the fast food world of large or popular burger chains, I give it 5 stars considering the under $2 price. I don't smoke weed, but if I did, I could see myself eating a bag of these little morsels after smoking a bowl, just like Harold and Kumar did in the movie. \\n\\nThe slider is the only thing that stood out. Again, I didn't care for the fries, and everything else was just okay. Service was decent, drink fountain was nothing special. Over all, 4 stars for White Castle, mostly because of their famous sliders.\", '西元1921年在堪薩斯州成立的 White Castle ，可是在美國無人不知無人不曉，距今將近一個世紀歷史的 速食 Fast Food 品牌，在近年來也到 賭城 Las Vegas 的賭城大道上開設分店，以全天候二十四小時的開業時間來提供給來自四面八方慕名而來的顧客。比起一般漢堡尺寸小了許多的特色小漢堡（又稱做Slider）不僅是陪伴著許多美國人成長的風味也是美國文化的縮影，在以其為主題的電影 Harold and Kumar Go to White Castle 中就可以感受其風潮與熱度，也是全美第一個以冷凍方式銷售到外州的漢堡。現在不用舟車勞頓前往東岸、也不用屈就於冷凍食物，趁著來到賭城的機會就可以品嚐到這個全美國資歷最深的經典速食風味。\\n\\n作為一個經典的速食品牌，相關的特色與紀念產品相信是許多粉絲們不可錯過的，而料理區就在點餐臺的後方，可以看到這個小漢堡特殊的料理方式，並不是採用一般香煎或火烤方式來料理漢堡肉，而是一種結合蒸煮同時又帶有煎的方式，並讓熱度與蒸氣把洋蔥的香甜味傳達到肉片上。\\n\\n一個小漢堡對一個成年男性來說，不用幾口就可以經鬆解決，特殊的烹煮方式讓品質尚可的肉質吃起來還挺有水分的，加上融化的起司帶來香濃的奶香與洋蔥的甜味，吃起來確實是挺有特色也是居住在加州的居民很少有機會品嚐到的口味。單吃小漢堡說起來並不難吃，但在當前眾多速食漢堡店都強調著食材品質和創新口味的衝擊下，相比起來食感薄弱了不少，但依靠著各種醬料的搭配來調整口位到也是挺有趣的。\\n\\n下次來到賭城，無論是早起的鳥兒、飢腸轆轆的食客、宵夜時間睡不著的夜貓子，都可以來到這間二十四小時經營的經典漢堡店，依照自己的食量來享用這個吃起來感覺不會太有負擔、卻是在美國速食業具有重高地位的可愛小漢堡。']\n"
     ]
    }
   ],
   "source": [
    "print ('Most %s similar reviews:' % n)\n",
    "print  (searched_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nbf = MultinomialNB()\n",
    "nbf.fit(vectors_train.toarray(),target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81235194038850844"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "nbf.score(vectors_train.toarray(),target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80715542778439708"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "nbf.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "vectors_train = vectors_train.toarray()\n",
    "\n",
    "lg = LogisticRegression()\n",
    "lg.fit(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84339061894301592"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "lg.score(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83342260310658811"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "lg.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'horrible',\n",
       " 'ok',\n",
       " 'bland',\n",
       " 'amazing',\n",
       " 'mediocre',\n",
       " 'disappointing',\n",
       " 'rude',\n",
       " 'best',\n",
       " 'terrible',\n",
       " 'okay',\n",
       " 'slow',\n",
       " 'lacked',\n",
       " 'average',\n",
       " 'poor',\n",
       " 'lacking',\n",
       " 'overpriced',\n",
       " 'meh',\n",
       " 'poisoning',\n",
       " 'tasteless']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_top_values(lg.coef_[0],n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the negative prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'horrible',\n",
       " 'ok',\n",
       " 'bland',\n",
       " 'mediocre',\n",
       " 'disappointing',\n",
       " 'rude',\n",
       " 'terrible',\n",
       " 'okay',\n",
       " 'slow',\n",
       " 'lacked',\n",
       " 'average',\n",
       " 'poor',\n",
       " 'lacking',\n",
       " 'overpriced',\n",
       " 'meh',\n",
       " 'poisoning',\n",
       " 'tasteless',\n",
       " 'alright',\n",
       " 'unfortunately']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_bottom_values(lg.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=20, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 5, min_samples_leaf = 20, n_jobs = -1)\n",
    "rfc.fit(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80161627255890078"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "rfc.score(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77830853819835377"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "rfc.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What do you see from the training score and the test score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: The number of estimators is not enough and the prediction score is even less than logistic regression. If we increase the number of estimators, the training time may be much longer but the result is expected to be improved. The test score is lower than the training score, this means that our model doesn't have overfitting problem yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Can you tell what features (words) are important by inspecting the RFC model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'delicious',\n",
       " 'like',\n",
       " 'best',\n",
       " 'great',\n",
       " 'asked',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'vegas',\n",
       " 'decent',\n",
       " 'didn',\n",
       " 'worst',\n",
       " 'okay',\n",
       " 'love',\n",
       " 'ok',\n",
       " 'order',\n",
       " 'bland',\n",
       " 'rude',\n",
       " 'definitely',\n",
       " 'dry']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(rfc.feature_importances_,n,words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Use cross validation to evaluate your classifiers\n",
    "\n",
    "[sklearn cross validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(lg,\n",
    "                            vectors_train,\n",
    "                            target_train,\n",
    "                            cv = 5,\n",
    "                            scoring=\"accuracy\")\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Use grid search to find best predictable classifier\n",
    "\n",
    "\n",
    "[sklearn grid search tutorial (with cross validation)](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "\n",
    "[sklearn grid search documentation (with cross validation)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be implemented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

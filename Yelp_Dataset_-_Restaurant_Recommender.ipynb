{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - Restaurant Recommender\n",
    "\n",
    "BitTiger DS501\n",
    "\n",
    "Nov 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "% matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0Qc1THNHSapDL7cv-ZzW5g</td>\n",
       "      <td>5</td>\n",
       "      <td>What can I say.. Wowzers! Probably one of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4LxKRRIikhr65GfPDW626w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>L8lo5SKXfZRlbn1bpPiC9w</td>\n",
       "      <td>5</td>\n",
       "      <td>Went here for guys weekend. Unbelievable. Ravi...</td>\n",
       "      <td>0</td>\n",
       "      <td>nT8zgjoc-PbdBoQsFEXFLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>30</td>\n",
       "      <td>6eUT3IwwWPP3CZkAhxqOIw</td>\n",
       "      <td>5</td>\n",
       "      <td>One word my friends: tableside!!! Yes, tablesi...</td>\n",
       "      <td>56</td>\n",
       "      <td>7RlyCglsIzhBn081inwvcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>3cnTdE45VrsS0o4cVhfGog</td>\n",
       "      <td>3</td>\n",
       "      <td>Located inside my favorite hotel Venetian, Del...</td>\n",
       "      <td>1</td>\n",
       "      <td>rOIrilMC7VFwFVBeQNiKMw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Steakhouses', 'Cajun/Creole', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>tYrSbjX3QgZGBZuQ3n8g6w</td>\n",
       "      <td>5</td>\n",
       "      <td>After the most incredible service, delicious m...</td>\n",
       "      <td>2</td>\n",
       "      <td>PiWlV_UC_-SXqyxQM9fAtw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                                       categories  avg_stars  cool  \\\n",
       "0  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     1   \n",
       "1  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     0   \n",
       "2  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0    52   \n",
       "3  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     1   \n",
       "4  ['Steakhouses', 'Cajun/Creole', 'Restaurants']        4.0     0   \n",
       "\n",
       "         date  funny               review_id  stars  \\\n",
       "0  2016-05-17      0  0Qc1THNHSapDL7cv-ZzW5g      5   \n",
       "1  2017-01-20      0  L8lo5SKXfZRlbn1bpPiC9w      5   \n",
       "2  2016-09-25     30  6eUT3IwwWPP3CZkAhxqOIw      5   \n",
       "3  2017-02-12      0  3cnTdE45VrsS0o4cVhfGog      3   \n",
       "4  2016-10-30      0  tYrSbjX3QgZGBZuQ3n8g6w      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  What can I say.. Wowzers! Probably one of the ...       0   \n",
       "1  Went here for guys weekend. Unbelievable. Ravi...       0   \n",
       "2  One word my friends: tableside!!! Yes, tablesi...      56   \n",
       "3  Located inside my favorite hotel Venetian, Del...       1   \n",
       "4  After the most incredible service, delicious m...       2   \n",
       "\n",
       "                  user_id  \n",
       "0  4LxKRRIikhr65GfPDW626w  \n",
       "1  nT8zgjoc-PbdBoQsFEXFLw  \n",
       "2  7RlyCglsIzhBn081inwvcg  \n",
       "3  rOIrilMC7VFwFVBeQNiKMw  \n",
       "4  PiWlV_UC_-SXqyxQM9fAtw  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean data and get rating data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relevant columns in the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 136735 entries, ---udAKDsn0yQXmzbWQNSw to zzvqVZTYs5VKxPc-IkRQ4A\n",
      "Columns: 4268 entries, --9e1ONYQuAa-CB_Rrw7Tw to zwNC-Ow4eIMan2__bS9-rg\n",
      "dtypes: int64(4268)\n",
      "memory usage: 4.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# Get business_id, user_id, stars for recommender\n",
    "df_utility = pd.pivot_table(data=df, \n",
    "                            values='stars', \n",
    "                            index='user_id', \n",
    "                            columns='business_id', \n",
    "                            fill_value=0)\n",
    "\n",
    "df_utility.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are many users that haven't given many reviews, exclude these users from the item-item similarity recommender\n",
    "\n",
    "**Q**: How do we recommend to these users anyways?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**A**: We can use item-item based collaborative filtering. Business as item, user as user. So we need to calculate the similarity between business first and then recommend. Or we can use U-V decomposition to build recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create utility matrix from records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<136735x4268 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in LInked List format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = df.user_id.value_counts()\n",
    "num_business = df.business_id.value_counts()\n",
    "#print(num_users,num_business)\n",
    "stars_mat = sparse.lil_matrix((num_users.shape[0], num_business.shape[0]))\n",
    "stars_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('user_id', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Item-Item similarity recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's reuse the ItemItemRecommender class derived from previous exercise\n",
    "\n",
    "Hint: we need to make modification to accommodate the dense numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136735, 4268)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('user_id', inplace = True)\n",
    "utility_mat = df_utility.as_matrix()\n",
    "utility_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-Item Similarity Matrix\n",
    "item_sim_mat = cosine_similarity(utility_mat.T)\n",
    "\n",
    "least_to_most_sim_indexes = np.argsort(item_sim_mat, axis=1)\n",
    "\n",
    "# Neighborhoods\n",
    "neighborhood_size = 75\n",
    "neighborhoods = least_to_most_sim_indexes[:, -neighborhood_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4268, 75)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhoods.shape\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's pick a lucky user\n",
    "user_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.          4.          3.          4.          3.          3.          4.\n",
      "  3.          3.          3.55785356  3.          4.          3.          3.\n",
      "  4.          3.47318803  3.          3.          4.          4.          3.\n",
      "  3.          3.          4.          4.          4.          3.          3.\n",
      "  3.          3.          3.          3.          3.          4.          4.\n",
      "  3.          3.          4.          3.          3.          4.          4.\n",
      "  4.          3.          4.          3.          3.          4.          3.\n",
      "  3.          3.          4.          3.          3.          4.          3.\n",
      "  3.          3.          3.          3.          3.          3.          4.\n",
      "  3.          3.          4.          3.          3.          4.          3.\n",
      "  3.          3.          4.          3.          3.49174105  3.          3.\n",
      "  4.          3.          3.          3.          4.          4.          3.\n",
      "  3.          3.          4.          3.          3.          3.          4.\n",
      "  3.          3.          3.          3.          3.          4.          3.\n",
      "  3.          4.          3.          3.          4.          3.          3.\n",
      "  3.          3.          3.          3.          4.          3.88590038\n",
      "  3.          3.52389887  3.          3.          4.          3.          3.\n",
      "  4.          3.          4.          3.          3.          3.          3.\n",
      "  3.3187534   3.          3.          3.          4.          4.          3.\n",
      "  3.          3.          3.          3.49332573  4.          4.          4.\n",
      "  3.          3.          3.          3.          4.          3.          4.\n",
      "  3.          3.35313823  3.          3.          3.          3.\n",
      "  3.36801672  3.          3.          4.          4.          4.          4.\n",
      "  3.          3.          4.          3.          3.          3.          4.\n",
      "  3.          4.          3.          3.          4.          3.          4.\n",
      "  4.          3.          3.          3.          4.          4.          3.\n",
      "  4.          3.          3.          3.          3.          4.          3.\n",
      "  3.          3.          4.          3.          4.          3.          3.\n",
      "  3.        ]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Execution time: 0.049621 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "n_users = utility_mat.shape[0]\n",
    "n_items = utility_mat.shape[1]\n",
    "\n",
    "start_time = time()\n",
    "items_rated_by_this_user = utility_mat[user_id].nonzero()[0]\n",
    "# Just initializing so we have somewhere to put rating preds\n",
    "out = np.zeros(n_items)\n",
    "for item_to_rate in range(n_items):\n",
    "    relevant_items = np.intersect1d(neighborhoods[item_to_rate],\n",
    "                                    items_rated_by_this_user,\n",
    "                                    assume_unique=True)  # assume_unique speeds up intersection op\n",
    "    #print(neighborhoods[item_to_rate])\n",
    "    #print(items_rated_by_this_user)\n",
    "    if len(relevant_items) != 0:\n",
    "        #print(relevant_items)\n",
    "        #print(utility_mat[user_id, relevant_items], '*', item_sim_mat[item_to_rate, relevant_items])\n",
    "        out[item_to_rate] = sum(utility_mat[user_id, relevant_items] * \\\n",
    "            item_sim_mat[item_to_rate, relevant_items]) / \\\n",
    "            item_sim_mat[item_to_rate, relevant_items].sum()\n",
    "    else:\n",
    "        out[item_to_rate] = np.nan\n",
    "\n",
    "\n",
    "print(out[~np.isnan(out)])\n",
    "pred_ratings = np.nan_to_num(out)\n",
    "print (pred_ratings)\n",
    "print(\"Execution time: %f seconds\" % (time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 3604, 1264, 29, 918, 2372, 2893, 3476, 484, 3908]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommend n movies\n",
    "n = 10\n",
    "\n",
    "# Get item indexes sorted by predicted rating\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))\n",
    "\n",
    "# Find items that have been rated by user\n",
    "items_rated_by_this_user = utility_mat[user_id].nonzero()[0]\n",
    "\n",
    "# We want to exclude the items that have been rated by user\n",
    "unrated_items_by_pred_rating_it = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "unrated_items_by_pred_rating_it[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend business name:  Beer Park\n",
      "recommend business name:  Leticia's Mexican Cocina\n",
      "recommend business name:  Squeeze In\n",
      "recommend business name:  Jaburritos\n",
      "recommend business name:  Yong Kang Street\n",
      "recommend business name:  Estiatorio Milos\n",
      "recommend business name:  Off The Strip at the LINQ\n",
      "recommend business name:  Gallagher's Steakhouse\n",
      "recommend business name:  Lobster ME\n",
      "recommend business name:  Pin-Up Pizza\n"
     ]
    }
   ],
   "source": [
    "recommend_business_id = df_utility.columns[unrated_items_by_pred_rating_it[-n:]].values\n",
    "for business in recommend_business_id:\n",
    "    print(\"recommend business name: \", df.loc[df.business_id == business].name.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrix Factorization recommender\n",
    "\n",
    "Take a look at Graphlab Create examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.89994527306\n",
      "2.46531960038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def fit_uvd(M,k):\n",
    "    # use TruncatedSVD to realize UVD\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=7, random_state=0)\n",
    "    svd.fit(M)\n",
    "\n",
    "    V = svd.components_\n",
    "    U = svd.transform(M) # effectively, it's doing: U = M.dot(V.T)\n",
    "    # we can ignore svd.singular_values_ for our purpose\n",
    "    \n",
    "    # why we can do this?\n",
    "    # recall: \n",
    "    # SVD start from u*s*v=M => u*s=M*v.T, where M*v.T is our transformation above to get U in UVD\n",
    "    # so the above U is effectively u*s in SVD\n",
    "    # that's why U*V = u*s*v = M our original matrix\n",
    "    # there are many ways to understand it!\n",
    "    # here we by-passed singular values.\n",
    "    \n",
    "    return U,V\n",
    "\n",
    "# decompose\n",
    "U,V = fit_uvd(utility_mat,200)\n",
    "\n",
    "# reconstruct\n",
    "ratings_mat_fitted = U.dot(V) # U*V\n",
    "\n",
    "# calculate errs\n",
    "errs = np.array((utility_mat-ratings_mat_fitted).flatten()).squeeze()\n",
    "mask = np.array(utility_mat.flatten()).squeeze()>0\n",
    "\n",
    "mse = np.mean(errs[mask]**2)\n",
    "average_abs_err = abs(errs[mask]).mean()\n",
    "print (mse)\n",
    "print (average_abs_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3908, 484, 3476, 2893, 2372, 918, 29, 1264, 3604, 44]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get recommendations for one user\n",
    "user_id = 3\n",
    "n = 10\n",
    "\n",
    "pred_ratings = ratings_mat_fitted[user_id,:]\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "items_rated_by_this_user = utility_mat[user_id].nonzero()[0]\n",
    "\n",
    "unrated_items_by_pred_rating_uv = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "unrated_items_by_pred_rating_uv[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend business name:  Culinary Dropout\n",
      "recommend business name:  Shake Shack\n",
      "recommend business name:  CUT by Wolfgang Puck\n",
      "recommend business name:  Nine Fine Irishmen\n",
      "recommend business name:  BabyStacks Cafe\n",
      "recommend business name:  Dog Haus\n",
      "recommend business name:  Rí Rá Irish Pub\n",
      "recommend business name:  The Bootlegger Italian Bistro\n",
      "recommend business name:  Scarpetta\n",
      "recommend business name:  Delmonico Steakhouse\n"
     ]
    }
   ],
   "source": [
    "recommend_business_id = df_utility.columns[unrated_items_by_pred_rating_uv[-n:]].values\n",
    "for business in recommend_business_id:\n",
    "    print(\"recommend business name: \", df.loc[df.business_id == business].name.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Other recommenders (optional)\n",
    "\n",
    "What are other ways you can build a better recommender?\n",
    "\n",
    "* Other features (have you noticed there are other features in the Yelp dataset, e.g. tips, etc.?)\n",
    "* Popularity-based\n",
    "* Content-based\n",
    "* Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Note\n",
    "> We can change the neighborhood_size to 200 or even larger to improve the item-item based recommender\n",
    "\n",
    "> We can increase the latent factor from 200 to 500 to improve the U-V decomposition recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
